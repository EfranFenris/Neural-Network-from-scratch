import os
import sys
import torch
import matplotlib.pyplot as plt

# ---------------------------------------------------------
# Make sure we can import from project root
# ---------------------------------------------------------
ROOT = os.path.dirname(os.path.dirname(__file__))
if ROOT not in sys.path:
    sys.path.insert(0, ROOT)

from models import MyFFNetworkForClassification
from train import train_one_epoch, evaluate
from dataset import load_mnist_processed


# ---------------------------------------------------------
# Build model for one (activation, init) configuration
# ---------------------------------------------------------
def build_model(activation: str, init: str, const_value: float = 0.0):
    """
    activation: "relu" or "sigmoid"
    init: "he", "xavier", or "const"
      - "he"/"xavier": use BaseNetwork initializers
      - "const": overwrite all weights with same constant value
    """
    if init in ("he", "xavier"):
        return MyFFNetworkForClassification(
            input_dim=784,       # MNIST 28x28 flattened
            hidden_dim=256,
            output_dim=10,       # 10 classes
            num_hidden_layers=2,
            init=init,
            activation=activation,
            use_batchnorm=False,
        )

    if init == "const":
        # Start with some init, then force all weights to same constant
        model = MyFFNetworkForClassification(
            input_dim=784,
            hidden_dim=256,
            output_dim=10,
            num_hidden_layers=2,
            init="xavier",
            activation=activation,
            use_batchnorm=False,
        )
        for W in model.W:
            W.data.fill_(const_value)
        for b in model.b:
            b.data.zero_()
        return model

    raise ValueError(f"Unknown init: {init}")


# ---------------------------------------------------------
# Train one configuration and collect curves
# ---------------------------------------------------------
def run_config(name, activation, init, Xtr, ytr, Xte, yte,
               lr=1e-2, epochs=10, batch_size=128):
    print(f"\n=== {name}: activation={activation}, init={init} ===")
    model = build_model(activation, init)

    train_losses, train_accs = [], []
    test_losses, test_accs = [], []

    for ep in range(1, epochs + 1):
        tr_loss, tr_acc = train_one_epoch(
            model,
            Xtr,
            ytr,
            lr=lr,
            batch_size=batch_size,
            task="clf",
        )
        te_loss, te_acc = evaluate(model, Xte, yte, task="clf")

        train_losses.append(tr_loss)
        train_accs.append(tr_acc)
        test_losses.append(te_loss)
        test_accs.append(te_acc)

        print(f"[{name}] epoch {ep:02d}  "
              f"train_loss={tr_loss:.4f}  train_acc={tr_acc:.3f}  "
              f"test_acc={te_acc:.3f}")

    return {
        "train_loss": train_losses,
        "train_acc": train_accs,
        "test_loss": test_losses,
        "test_acc": test_accs,
    }


# ---------------------------------------------------------
# Main: run all four configs from the table
# ---------------------------------------------------------
def main():
    os.makedirs(os.path.join(ROOT, "graphs_exp"), exist_ok=True)

        # ----- Load MNIST (processed tensors) -----
    torch.manual_seed(0)
    Xtr, ytr, Xte, yte = load_mnist_processed()

    # SUBSAMPLE FOR SPEED (e.g. 10k train, 2k test)
    max_train = 10000
    max_test = 2000
    if Xtr.shape[0] > max_train:
        Xtr = Xtr[:max_train]
        ytr = ytr[:max_train]
    if Xte.shape[0] > max_test:
        Xte = Xte[:max_test]
        yte = yte[:max_test]
    print(f"Using {Xtr.shape[0]} train and {Xte.shape[0]} test samples.")
    # Configs exactly as in the assignment
    configs = [
        ("Sigmoid_Xavier", "sigmoid", "xavier"),
        ("ReLU_He",        "relu",    "he"),
        ("ReLU_Xavier",    "relu",    "xavier"),
        ("Sigmoid_Const",  "sigmoid", "const"),
    ]

    results = {}
    for name, act, init in configs:
        results[name] = run_config(name, act, init, Xtr, ytr, Xte, yte)

    # ----- Plot: training loss -----
    plt.figure()
    for name, _, _ in configs:
        plt.plot(results[name]["train_loss"], label=name)
    plt.xlabel("Epoch")
    plt.ylabel("Train loss (cross-entropy)")
    plt.title("Ex2: Activation–Initialization (MNIST) — train loss")
    plt.legend()
    plt.tight_layout()
    out_loss = os.path.join(ROOT, "graphs_exp", "ex2_act_init_train_loss.png")
    plt.savefig(out_loss)
    plt.close()

    # ----- Plot: test accuracy -----
    plt.figure()
    for name, _, _ in configs:
        plt.plot(results[name]["test_acc"], label=name)
    plt.xlabel("Epoch")
    plt.ylabel("Test accuracy")
    plt.title("Ex2: Activation–Initialization (MNIST) — test accuracy")
    plt.legend()
    plt.tight_layout()
    out_acc = os.path.join(ROOT, "graphs_exp", "ex2_act_init_test_acc.png")
    plt.savefig(out_acc)
    plt.close()

    print("\nSaved plots:")
    print(" ", out_loss)
    print(" ", out_acc)
    print("\nUse these curves to answer: Which configuration worked best and why?")


if __name__ == "__main__":
    main()